{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitcompvisconda2d3448796e3e49d498304dbbfe353f71",
   "display_name": "Python 3.7.6 64-bit ('compvis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from sklearn import tree, metrics\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.util import crop\n",
    "from skimage import io, color\n",
    "from math import floor, ceil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import json\n",
    "from LoadLocalCOCO import LoadLocalCOCO as llc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(qlist):\n",
    "    return [y for x in qlist for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance=\"annotations/instances_train2017.json\"\n",
    "val_instance=\"annotations/instances_val2017.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_path = \"D:/FSR/COCO/train2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_train = llc(train_instance, coco_path)\n",
    "coco_val = llc(val_instance, coco_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_n = [coco_train.get_number_of_images_per_category(x) for x in classes]\n",
    "# val_n = [coco_val.get_number_of_images_per_category(x) for x in classes]\n",
    "# print(f'Training:> \\t Dog: {train_n[0]} \\t Cat: {train_n[1]}')\n",
    "# print(f'Validation:> \\t Dog: {val_n[0]} \\t Cat: {val_n[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "5508it [05:51, 15.69it/s]\n",
      "2it [00:00, 16.54it/s]Broken images: [7125, 16775, 24247, 24247, 55296, 47386, 69468, 35613, 77325, 12696, 22427, 26321, 54957, 790, 1360, 55478, 42341, 57631, 2400, 10276, 94049, 58741, 5782, 44613, 58741, 24159, 44613, 29176] images\n",
      "4768it [04:57, 16.02it/s]Broken images: [5617, 711, 39171, 9413, 46749, 18211, 26375, 26375, 26375, 66041] images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "for category in classes:\n",
    "    data = coco_train.get_cropped_images_flatten_and_resized(category, resize=(64, 64))\n",
    "    data_train.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5480, 12288)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "np.shape(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = len(data_train[0])*[1]+len(data_train[1])*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10238,)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "np.shape(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = flatten_list(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10238, 12288)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "np.shape(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 25)\n",
    "pca.fit(X_train)\n",
    "reduced_X_train_pca, reduced_X_test_pca = pca.transform(X_train), pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7678, 24)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "np.shape(reduced_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7678, 67500)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=7, random_state=0, whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class FastICA in module sklearn.decomposition._fastica:\n\nclass FastICA(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n |  FastICA(n_components=None, algorithm='parallel', whiten=True, fun='logcosh', fun_args=None, max_iter=200, tol=0.0001, w_init=None, random_state=None)\n |  \n |  FastICA: a fast algorithm for Independent Component Analysis.\n |  \n |  Read more in the :ref:`User Guide <ICA>`.\n |  \n |  Parameters\n |  ----------\n |  n_components : int, optional\n |      Number of components to use. If none is passed, all are used.\n |  \n |  algorithm : {'parallel', 'deflation'}\n |      Apply parallel or deflational algorithm for FastICA.\n |  \n |  whiten : boolean, optional\n |      If whiten is false, the data is already considered to be\n |      whitened, and no whitening is performed.\n |  \n |  fun : string or function, optional. Default: 'logcosh'\n |      The functional form of the G function used in the\n |      approximation to neg-entropy. Could be either 'logcosh', 'exp',\n |      or 'cube'.\n |      You can also provide your own function. It should return a tuple\n |      containing the value of the function, and of its derivative, in the\n |      point. Example:\n |  \n |      def my_g(x):\n |          return x ** 3, (3 * x ** 2).mean(axis=-1)\n |  \n |  fun_args : dictionary, optional\n |      Arguments to send to the functional form.\n |      If empty and if fun='logcosh', fun_args will take value\n |      {'alpha' : 1.0}.\n |  \n |  max_iter : int, optional\n |      Maximum number of iterations during fit.\n |  \n |  tol : float, optional\n |      Tolerance on update at each iteration.\n |  \n |  w_init : None of an (n_components, n_components) ndarray\n |      The mixing matrix to be used to initialize the algorithm.\n |  \n |  random_state : int, RandomState instance or None, optional (default=None)\n |      If int, random_state is the seed used by the random number generator;\n |      If RandomState instance, random_state is the random number generator;\n |      If None, the random number generator is the RandomState instance used\n |      by `np.random`.\n |  \n |  Attributes\n |  ----------\n |  components_ : 2D array, shape (n_components, n_features)\n |      The linear operator to apply to the data to get the independent\n |      sources. This is equal to the unmixing matrix when ``whiten`` is\n |      False, and equal to ``np.dot(unmixing_matrix, self.whitening_)`` when\n |      ``whiten`` is True.\n |  \n |  mixing_ : array, shape (n_features, n_components)\n |      The pseudo-inverse of ``components_``. It is the linear operator\n |      that maps independent sources to the data.\n |  \n |  mean_ : array, shape(n_features)\n |      The mean over features. Only set if `self.whiten` is True.\n |  \n |  n_iter_ : int\n |      If the algorithm is \"deflation\", n_iter is the\n |      maximum number of iterations run across all components. Else\n |      they are just the number of iterations taken to converge.\n |  \n |  whitening_ : array, shape (n_components, n_features)\n |      Only set if whiten is 'True'. This is the pre-whitening matrix\n |      that projects data onto the first `n_components` principal components.\n |  \n |  Examples\n |  --------\n |  >>> from sklearn.datasets import load_digits\n |  >>> from sklearn.decomposition import FastICA\n |  >>> X, _ = load_digits(return_X_y=True)\n |  >>> transformer = FastICA(n_components=7,\n |  ...         random_state=0)\n |  >>> X_transformed = transformer.fit_transform(X)\n |  >>> X_transformed.shape\n |  (1797, 7)\n |  \n |  Notes\n |  -----\n |  Implementation based on\n |  *A. Hyvarinen and E. Oja, Independent Component Analysis:\n |  Algorithms and Applications, Neural Networks, 13(4-5), 2000,\n |  pp. 411-430*\n |  \n |  Method resolution order:\n |      FastICA\n |      sklearn.base.TransformerMixin\n |      sklearn.base.BaseEstimator\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, n_components=None, algorithm='parallel', whiten=True, fun='logcosh', fun_args=None, max_iter=200, tol=0.0001, w_init=None, random_state=None)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit(self, X, y=None)\n |      Fit the model to X.\n |      \n |      Parameters\n |      ----------\n |      X : array-like, shape (n_samples, n_features)\n |          Training data, where n_samples is the number of samples\n |          and n_features is the number of features.\n |      \n |      y : Ignored\n |      \n |      Returns\n |      -------\n |      self\n |  \n |  fit_transform(self, X, y=None)\n |      Fit the model and recover the sources from X.\n |      \n |      Parameters\n |      ----------\n |      X : array-like, shape (n_samples, n_features)\n |          Training data, where n_samples is the number of samples\n |          and n_features is the number of features.\n |      \n |      y : Ignored\n |      \n |      Returns\n |      -------\n |      X_new : array-like, shape (n_samples, n_components)\n |  \n |  inverse_transform(self, X, copy=True)\n |      Transform the sources back to the mixed data (apply mixing matrix).\n |      \n |      Parameters\n |      ----------\n |      X : array-like, shape (n_samples, n_components)\n |          Sources, where n_samples is the number of samples\n |          and n_components is the number of components.\n |      copy : bool (optional)\n |          If False, data passed to fit are overwritten. Defaults to True.\n |      \n |      Returns\n |      -------\n |      X_new : array-like, shape (n_samples, n_features)\n |  \n |  transform(self, X, copy=True)\n |      Recover the sources from X (apply the unmixing matrix).\n |      \n |      Parameters\n |      ----------\n |      X : array-like, shape (n_samples, n_features)\n |          Data to transform, where n_samples is the number of samples\n |          and n_features is the number of features.\n |      \n |      copy : bool (optional)\n |          If False, data passed to fit are overwritten. Defaults to True.\n |      \n |      Returns\n |      -------\n |      X_new : array-like, shape (n_samples, n_components)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.TransformerMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : mapping of string to any\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as pipelines). The latter have parameters of the form\n |      ``<component>__<parameter>`` so that it's possible to update each\n |      component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : object\n |          Estimator instance.\n\n"
     ]
    }
   ],
   "source": [
    "help(FastICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FastICA(algorithm='parallel', fun='logcosh', fun_args=None, max_iter=200,\n",
       "        n_components=7, random_state=0, tol=0.0001, w_init=None, whiten=True)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "ica.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X_train_ica = ica.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X_test_ica = ica.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=25, n_iter=5,\n",
       "             random_state=None, tol=0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 25)\n",
    "svd.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X_train_svd, reduced_X_test_svd = svd.transform(X_train), svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}